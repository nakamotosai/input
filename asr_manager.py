"""
ASRç®¡ç†æ¨¡å— - ä¸“æ³¨äº Sherpa-ONNX å¼•æ“çš„æç®€é©±åŠ¨
ä¸å†åŒ…å«å†—ä½™çš„æ ‡ç‚¹æ¨¡å‹é€»è¾‘å’Œå¤æ‚çš„æ­£åˆ™å¯å‘å¼ç®—æ³•

ä¿®å¤ï¼šåœ¨ä¸»è¿›ç¨‹ä¸­è§£ææ¨¡å‹è·¯å¾„åä¼ é€’ç»™å­è¿›ç¨‹ï¼Œé¿å…å­è¿›ç¨‹è·¯å¾„è§£æé—®é¢˜
"""

import os
import re
import gc
import sys
import numpy as np
import multiprocessing
import traceback
import threading
from abc import ABC, abstractmethod
from typing import Optional, List
from PyQt6.QtCore import QObject, pyqtSignal, QThread, pyqtSlot

from model_config import (
    get_model_config, 
    ASREngineType, 
    ASROutputMode
)

# è®¾ç½®ç¯å¢ƒå˜é‡ï¼Œè§£å†³å¯èƒ½çš„OpenMPåº“å†²çª
os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"

def clean_asr_output(text: str, mode: str = "raw", is_insertion: bool = False) -> str:
    """
    æ¸…ç†ASRè¾“å‡ºæ–‡æœ¬
    mode: "raw" ä»…åŸºç¡€æ¸…ç†æ ‡ç­¾; "cleaned" é¢å¤–æ‰§è¡Œæ­£åˆ™å‡€åŒ–
    is_insertion: å¦‚æœä¸º Trueï¼Œåˆ™å‰¥ç¦»æœ«å°¾å¥å·ï¼›å¦‚æœä¸º Falseï¼Œåˆ™ä¿ç•™ã€‚
    """
    if not text:
        return ""
        
    # [Fix] 1. é¢„å¤„ç†ï¼šå»é™¤é¦–å°¾ç©ºç™½
    text = text.strip()
    if not text:
        return ""
        
    # [Fix] 2. å†…å®¹æ•ˆéªŒï¼šå¿…é¡»åŒ…å«è‡³å°‘ä¸€ä¸ªæœ‰æ•ˆå­—ç¬¦ (ä¸­æ–‡ã€æ—¥æ–‡ã€éŸ©æ–‡ã€å­—æ¯ã€æ•°å­—)
    # é˜²æ­¢ Sherpa-ONNX å¹»è§‰è¾“å‡ºçº¯æ ‡ç‚¹ (å¦‚ "ã€‚" æˆ– "..." æˆ– "?")
    has_content = re.search(r'[\u4e00-\u9fa5\u3040-\u30ff\u31f0-\u31ff\uac00-\ud7af\w]', text)
    if not has_content:
        return ""
        
    # 3. åŸºç¡€æ¸…ç†ï¼šç§»é™¤æ‰€æœ‰æ¨¡å‹å†…ç½®æ ‡ç­¾ <|xxx|> å’Œ [xxx]
    text = re.sub(r'<\|.*?\|>', '', text)
    text = re.sub(r'\[.*?\]', '', text)
    
    # 2. åŸºç¡€æ ‡ç‚¹ä¼˜åŒ– (æ— è®ºä»€ä¹ˆæ¨¡å¼éƒ½æ‰§è¡Œ)
    # A. æ™ºèƒ½æ ‡ç‚¹å¤„ç† (Smart Punctuation)
    # [Removed] åºŸå¼ƒâ€œæ‰€ä»¥/ä½†æ˜¯â€ç­‰åç¼€ä¸åŠ å¥å·çš„é€»è¾‘
    incomplete_markers = r'$^' # æ°¸è¿œä¸åŒ¹é…

    # é€»è¾‘ 1: å¤„ç†å¤šå¥é€»è¾‘ - â€œç•™é€—å»å¥â€
    # å¦‚æœæ£€æµ‹åˆ°å†…éƒ¨å¥å·ï¼Œå°†å…¶æ›¿æ¢ä¸ºé€—å· (ç”¨æˆ·åé¦ˆï¼šä¸¤å¥è¯ä¹‹é—´çš„é€—å·è¿˜æ˜¯éœ€è¦)
    if text:
        # A. æŸ¥æ‰¾æ‰€æœ‰å¥å·ï¼Œå¦‚æœåé¢è¿˜æœ‰æ–‡å­—ï¼Œåˆ™å°†å…¶æ›¿æ¢ä¸ºé€—å·
        text = re.sub(r'ã€‚(?!$)', 'ï¼Œ', text)
        
        # B. å¤„ç†æœ«å°¾å¥å·
        # B. å¤„ç†æœ«å°¾å¥å·
        if is_insertion:
            # æ’å…¥æ¨¡å¼ï¼šå½»åº•å‰¥ç¦»æœ«å°¾å¥å· (åŒ…æ‹¬å…¨è§’å’ŒåŠè§’)
            text = text.rstrip('ã€‚ï¼ï¼Ÿ.?!')
        else:
            # éæ’å…¥æ¨¡å¼ (æ–°èµ·ä¸€æ®µ æˆ– è¿½åŠ )ï¼š
            # å¦‚æœè¯†åˆ«ç»“æœæœ¬æ¥æ²¡æœ‰å¥å·ï¼Œå¼ºåˆ¶è¡¥å…¨
            # å¿…é¡»æ£€æŸ¥å…¨è§’å’ŒåŠè§’æ ‡ç‚¹ï¼Œé˜²æ­¢ "test." å˜æˆ "test.ã€‚"
            if text and not (text.endswith(('ã€‚', 'ï¼', 'ï¼Ÿ', '.', '!', '?'))):
                # åªæœ‰å½“å®ƒä¸åƒæ˜¯ä¸€ä¸ªæœªå®Œæˆçš„å¥å­æ—¶æ‰åŠ 
                if not re.search(incomplete_markers, text):
                    text += "ã€‚"

    # é€»è¾‘ 2: å¤„ç†æ˜¾å¼çš„â€œæœªå®Œæˆâ€æ ‡è¯†è¯ (æ— è®ºæ˜¯å¦æ’å…¥éƒ½å»æ‰æ ‡ç‚¹)
    if re.search(incomplete_markers, text):
        text = text.rstrip('ã€‚ï¼ï¼Ÿ')
        
    # é€»è¾‘ 3: çŸ­æ–‡æœ¬ç‰‡æ®µæ·±åº¦ä¿æŠ¤ (å¦‚æœæ˜¯æ’å…¥æ¨¡å¼ä¸”çŸ­è¯­ï¼Œæ›´å€¾å‘äºå»æ‰æ‰€æœ‰ç»“å°¾æ ‡ç‚¹)
    if is_insertion:
        core_text = text.rstrip('ã€‚ï¼ï¼Ÿ')
        if core_text and len(core_text) <= 5:
            sentence_particles = r'.*[äº†å—å§å‘¢å•Šå‘€å“‡å˜›å“’å–”å–½å“©]$|.*[ã€‚ï¼Œï¼ï¼Ÿ]$|.*[0-9a-zA-Z]$'
            if not re.match(sentence_particles, core_text):
                text = core_text

    # å¼ºåˆ¶ç§»é™¤è¿ç»­é‡å¤æ ‡ç‚¹ (ä¾‹å¦‚ "ã€‚ã€‚" -> "ã€‚" æˆ– ".ã€‚" -> "ã€‚")
    text = re.sub(r'([ã€‚ï¼Œï¼ï¼Ÿ.?!])\1+', r'\1', text)

    # 2. å¦‚æœæ˜¯"æ­£åˆ™è¡¨è¾¾ (Cleaned)"æ¨¡å¼ï¼Œæ‰§è¡Œæ›´æ¿€è¿›çš„å‡€åŒ–
    if mode == ASROutputMode.CLEANED.value:
        # C. (å·²ç§»é™¤) å¼ºåˆ¶ä¸­æ—¥è‹±æ–‡æ··æ’ç©ºæ ¼ä¼˜åŒ– - å“åº”ç”¨æˆ·åé¦ˆç§»é™¤
        # text = re.sub(r'([\u4e00-\u9fa5])([a-zA-Z0-9])', r'\1 \2', text)
        # text = re.sub(r'([a-zA-Z0-9])([\u4e00-\u9fa5])', r'\1 \2', text)
        
        # D. ç§»é™¤å¥é¦–å¥å°¾çš„ç©ºç™½å­—ç¬¦
        text = text.strip()
    
    # E. Emoji æ¨¡å¼
    try:
        from model_config import EmojiMode, get_model_config
        # é‡æ–°è·å–é…ç½®ä»¥ç¡®ä¿æœ€æ–°
        cfg = get_model_config()
        mode = cfg.emoji_mode
        
        if mode == EmojiMode.TRIGGER.value:
            # è¯­éŸ³è§¦å‘æ¨¡å¼ï¼šæ£€æµ‹å¥æœ«å…³é”®è¯å¹¶æ›¿æ¢
            triggers = {
                "ç¬‘å“­": "ğŸ˜‚", "å“ˆå“ˆ": "ğŸ˜„", "å¼€å¿ƒ": "ğŸ˜Š", 
                "ç‚¹èµ": "ğŸ‘", "æ˜Ÿæ˜Ÿ": "ğŸŒŸ", "çˆ±å¿ƒ": "â¤ï¸", 
                "ç–‘é—®": "â“", "ç”Ÿæ°”": "ğŸ˜ ", "æµæ³ª": "ğŸ˜­",
                "é¼“æŒ": "ğŸ‘", "åº†ç¥": "ğŸ‰", "åˆå": "ğŸ™",
                "åŠ æ²¹": "ğŸ’ª", "æ»‘ç¨½": "ğŸ¤ª", "æ€è€ƒ": "ğŸ¤”"
            }
            # æ£€æŸ¥å¥æœ« (å¿½ç•¥æœ€åçš„æ ‡ç‚¹)
            # å…ˆå‰¥ç¦»æ ‡ç‚¹
            content = text
            suffix = ""
            if content and content[-1] in "ã€‚ï¼Œï¼ï¼Ÿ":
                suffix = content[-1]
                content = content[:-1]
                
            for k, v in triggers.items():
                if content.endswith(k):
                    # ç§»é™¤å…³é”®è¯
                    prefix = content[:-len(k)]
                    # ç§»é™¤å…³é”®è¯å‰é¢çš„æ ‡ç‚¹ (å¦‚ "æœ‰é“ç†ï¼Œ" -> "æœ‰é“ç†")
                    if prefix.endswith(("ï¼Œ", "ã€‚")):
                        prefix = prefix[:-1]
                    
                    content = prefix + v
                    # è§¦å‘æ¨¡å¼ä¸‹ï¼ŒEmoji è§†ä½œå¥æœ«ï¼Œä¸å†è¿½åŠ åŸæœ‰çš„å¥å°¾æ ‡ç‚¹
                    text = content 
                    break

        elif mode == EmojiMode.AUTO.value:
            # è‡ªåŠ¨æ¨¡å¼ï¼šæ ¹æ®è¯­æ°”è¯æ·»åŠ ï¼Œé»˜è®¤ç¬‘å“­
            # æƒ…æ„Ÿå…³é”®è¯æ˜ å°„ï¼ˆç®€åŒ–çš„å…³é”®è¯åˆ—è¡¨ï¼‰
            sentiment_map = {
                "ğŸ˜„": ["å“ˆå“ˆ", "å˜¿å˜¿", "å¼€å¿ƒ", "é«˜å…´", "å¿«ä¹", "å¥½ç¬‘"],
                "ğŸ˜Š": ["ä½ å¥½", "è°¢è°¢", "æ”¶åˆ°", "å¥½çš„", "æ²¡é—®é¢˜", "å–œæ¬¢"],
                "ğŸ‘": ["ä¸é”™", "å‰å®³", "ç‰›", "èµ", "æ”¯æŒ", "é¡ºåˆ©"],
                "ğŸ˜­": ["éš¾è¿‡", "ä¼¤å¿ƒ", "å‘œå‘œ", "æƒ¨", "ç—›è‹¦"],
                "ğŸ˜ ": ["è®¨åŒ", "çƒ¦", "æ»š", "æ°”æ­»"],
                "ğŸ™": ["æ‹œæ‰˜", "éº»çƒ¦", "æ„Ÿè°¢", "è¾›è‹¦"],
                "ğŸ¤”": ["è§‰å¾—", "æƒ³", "å¯èƒ½", "æ˜¯å¦", "ä¸ºä»€ä¹ˆ"],
                "ğŸ˜‚": [] # Default fallback
            }
            
            found_emoji = None
            for emoji, keywords in sentiment_map.items():
                for kw in keywords:
                    if kw in text:
                        found_emoji = emoji
                        break
                if found_emoji: break
            
            if not found_emoji:
                found_emoji = "ğŸ˜‚"
            
            # å¦‚æœåŸæ–‡ä»¥å¥å·æˆ–é€—å·ç»“å°¾ï¼Œå…ˆç§»é™¤ï¼Œå†åŠ  Emoji
            if text.endswith(("ã€‚", "ï¼Œ")):
                text = text[:-1]
            text += found_emoji
            
    except Exception as e:
        print(f"[ASRManager] Emoji error: {e}")

    # [Task] è¯­è¨€æ•æ„Ÿå‹ç©ºæ ¼å¤„ç†
    # å¦‚æœåŒ…å«ä¸­æ–‡æˆ–æ—¥æ–‡å­—ç¬¦ï¼Œåˆ™å¼ºåˆ¶ç§»é™¤æ‰€æœ‰å†…éƒ¨ç©ºæ ¼ï¼ˆä¸­æ—¥æ–‡åˆ†è¯æ®‹ç•™ï¼‰
    # å¦‚æœæ˜¯çº¯è‹±æ–‡/è¥¿æ–‡ï¼Œåˆ™ä¿ç•™å•ç©ºæ ¼ï¼ˆä¿æŠ¤è‹±æ–‡å•è¯é—´è·ï¼‰
    has_cjk = re.search(r'[\u4e00-\u9fa5\u3040-\u30ff\u31f0-\u31ff]', text)
    if has_cjk:
        text = re.sub(r'\s+', '', text)
    else:
        # çº¯è‹±æ–‡æ¨¡å¼ï¼šä»…å°†å¤šé‡ç©ºæ ¼å‹ç¼©ä¸ºå•ç©ºæ ¼
        text = re.sub(r'\s+', ' ', text)
        
    return text.strip()

# ===== æ ¸å¿ƒå¼•æ“ä»£ç† (é‡æ„ä¸ºè¿›ç¨‹å†…çº¿ç¨‹å®‰å…¨æ¨¡å¼) =====
class OnnxASREngine:
    def __init__(self):
        self.is_loaded = False
        self.recognizer = None
        self._lock = threading.Lock()
    
    def load(self, model_path: str) -> bool:
        """
        åŠ è½½ ASR æ¨¡å‹ (åœ¨ä¸»è¿›ç¨‹ä¸­æ‰§è¡Œï¼Œè§„é¿å¤šè¿›ç¨‹æƒé™åŠç¯å¢ƒå†²çª)
        """
        try:
            import os
            import sherpa_onnx
            
            # éªŒè¯æ¨¡å‹è·¯å¾„
            if not model_path or not os.path.exists(model_path):
                print(f"[ASR-Engine] æ¨¡å‹è·¯å¾„æ— æ•ˆ: {model_path}")
                return False
            
            print(f"[ASR-Engine] æ­£åœ¨ä¸»è¿›ç¨‹åŠ è½½ Sherpa-ONNX æ¨¡å‹: {model_path}")

            # å®šä¹‰æ ¸å¿ƒæ–‡ä»¶
            model_file = os.path.join(model_path, "model.int8.onnx")
            if not os.path.exists(model_file):
                model_file = os.path.join(model_path, "model.onnx")
                
            tokens_file = os.path.join(model_path, "tokens.txt")
            
            if not os.path.exists(model_file) or not os.path.exists(tokens_file):
                print(f"[ASR-Engine] æ ¸å¿ƒæ–‡ä»¶ç¼ºå¤±: {model_file} æˆ– {tokens_file}")
                return False

            # åˆå§‹åŒ–è¯†åˆ«å™¨
            self.recognizer = sherpa_onnx.OfflineRecognizer.from_sense_voice(
                model=model_file,
                tokens=tokens_file,
                use_itn=True,
                language="auto",
                num_threads=4
            )
            
            self.is_loaded = True
            print(f"[ASR-Engine] æ¨¡å‹åŠ è½½æˆåŠŸ")
            return True
                
        except Exception as e:
            print(f"[ASR-Engine] åŠ è½½å¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def transcribe(self, audio_data) -> str:
        if not self.is_loaded or not self.recognizer:
            return ""
        try:
            # è½¬æ¢æ•°æ®ä¸ºæ•°ç»„
            import numpy as np
            audio_array = np.array(audio_data, dtype=np.float32)
            
            with self._lock:
                stream = self.recognizer.create_stream()
                stream.accept_waveform(16000, audio_array)
                self.recognizer.decode_stream(stream)
                text = stream.result.text
            return text
        except Exception as e:
            print(f"[ASR-Engine] è½¬å†™å¤±è´¥: {e}")
            return ""

    def unload(self):
        with self._lock:
            self.recognizer = None
            self.is_loaded = False

# ===== ASR Worker & Manager =====
class ASRWorker(QObject):
    model_ready = pyqtSignal()
    result_ready = pyqtSignal(str)
    error_occurred = pyqtSignal(str)
    status_changed = pyqtSignal(str)
    
    def __init__(self):
        super().__init__()
        self.config = get_model_config()
        self.engine = OnnxASREngine()
    
    @pyqtSlot()
    def load_model(self):
        # åœ¨ä¸»è¿›ç¨‹ä¸­è§£ææ¨¡å‹è·¯å¾„
        model_path = self.config.get_asr_model_path()
        
        if not model_path:
            self.error_occurred.emit("æœªæ‰¾åˆ°è¯­éŸ³è¯†åˆ«æ¨¡å‹")
            return
            
        if not os.path.exists(model_path):
            self.error_occurred.emit(f"æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {model_path}")
            return
        
        self.status_changed.emit(f"æ­£åœ¨å¯åŠ¨è¯­éŸ³å¼•æ“...")
        print(f"[ASRWorker] è§£æçš„æ¨¡å‹è·¯å¾„: {model_path}")
        
        if self.engine.load(model_path):
            self.status_changed.emit("è¯­éŸ³å¼•æ“å·²å°±ç»ª")
            self.model_ready.emit()
        else:
            self.error_occurred.emit("è¯­éŸ³å¼•æ“åŠ è½½å¤±è´¥")
    
    @pyqtSlot(object, bool)
    def transcribe(self, audio_data, is_insertion=False):
        if not self.engine.is_loaded: return
        try:
            raw_text = self.engine.transcribe(audio_data)
            if raw_text:
                mode = self.config.asr_output_mode
                cleaned_text = clean_asr_output(raw_text, mode=mode, is_insertion=is_insertion)
                self.result_ready.emit(cleaned_text)
        except:
            pass

class ASRManager(QObject):
    _instance = None
    _initialized = False
    
    model_ready = pyqtSignal()
    result_ready = pyqtSignal(str)
    error = pyqtSignal(str)
    status_changed = pyqtSignal(str)
    
    _sig_load_model = pyqtSignal()
    _sig_transcribe = pyqtSignal(object, bool)
    
    def __new__(cls, *args, **kwargs):
        if not cls._instance:
            cls._instance = super(ASRManager, cls).__new__(cls)
        return cls._instance
    
    def __init__(self):
        if not ASRManager._initialized:
            super().__init__()
            ASRManager._initialized = True
            self.worker = ASRWorker()
            self.thread = QThread()
            self.worker.moveToThread(self.thread)
            
            self.worker.model_ready.connect(self.model_ready.emit)
            self.worker.result_ready.connect(self.result_ready.emit)
            self.worker.error_occurred.connect(self.error.emit)
            self.worker.status_changed.connect(self.status_changed.emit)
            self._sig_load_model.connect(self.worker.load_model)
            self._sig_transcribe.connect(self.worker.transcribe)
            self.thread.start()

    def start(self): self._sig_load_model.emit()
    
    def transcribe_async(self, audio_data, is_insertion=False):
        data = audio_data.tolist() if isinstance(audio_data, np.ndarray) else audio_data
        self._sig_transcribe.emit(data, is_insertion)
    
    def cleanup(self):
        if self.thread.isRunning():
            self.thread.quit()
            self.thread.wait()
        if self.worker.engine: self.worker.engine.unload()
